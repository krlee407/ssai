{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data load\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import json\n",
    "import pickle\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "\n",
    "RANDOM_SEED = 2018\n",
    "n_core = 4\n",
    "\n",
    "ori_data = pd.read_csv('dataset_kor/교통사망사고정보/Kor_Train_교통사망사고정보(12.1~17.6).csv', encoding='euc-kr', engine='python')\n",
    "val_data = pd.read_csv('val_refine.csv', encoding='euc-kr', engine='python')\n",
    "test_data = pd.read_csv('test_kor.csv', encoding='euc-kr', engine='python')\n",
    "\n",
    "train_data = ori_data.dropna()\n",
    "target_col_list = [i.strip() for i in \n",
    "                   '사상자수, 사망자수, 중상자수, 경상자수, 부상신고자수, 주야, 요일, 발생지시도, 발생지시군구, \\\n",
    "                   사고유형_대분류, 사고유형_중분류, 법규위반, 도로형태_대분류, 도로형태, \\\n",
    "                   당사자종별_1당_대분류, 당사자종별_2당_대분류'.split(',')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# local function\n",
    "\n",
    "from math import exp\n",
    "\n",
    "def official_numerical_score(pred, real, B=1, s=1):\n",
    "    return B * sum([exp(-((n-m)/s)**2) for n, m in zip(pred, real)])\n",
    "\n",
    "def official_categorical_score(pred, real, C=1):\n",
    "    return C * sum([1 if ci == di else 0 for ci, di in zip(pred, real)])\n",
    "\n",
    "def refine_val(df, target_col, dependent_col_list):\n",
    "    for t_col in target_col_list:\n",
    "        df = df[[isinstance(x, float) and np.isnan(x) for x in df[t_col]]]\n",
    "    for d_col in dependent_col_list:\n",
    "        df = df[[not (isinstance(x, float) and np.isnan(x)) for x in df[d_col]]]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# templete function\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "def preprocessing(data):\n",
    "    onehot_col = []\n",
    "\n",
    "    for col in data.columns:\n",
    "        if isinstance(data[col].values[0], str):\n",
    "            onehot_col.append(col)\n",
    "\n",
    "    data = pd.get_dummies(data, prefix=onehot_col)\n",
    "    return data\n",
    "\n",
    "class CustomHyperParameterTuner:\n",
    "    def __init__(self, model, params, eval_fun, greater_is_better=True, cv=5):\n",
    "        self.model = model\n",
    "        self.params = params\n",
    "        self.eval_fun = eval_fun\n",
    "        self.greater_is_better = greater_is_better\n",
    "        self.cv = cv\n",
    "        self._best_model = None\n",
    "        self.best_params_ = None\n",
    "        self.best_score_ = None\n",
    "\n",
    "    def fit(self, X, y, val_X=None, val_y=None):\n",
    "        if val_X is None or val_y is None:\n",
    "            self.model = GridSearchCV(self.model, self.params, cv=self.cv,\n",
    "                                      scoring=make_scorer(self.eval_fun,\n",
    "                                                          greater_is_better=self.greater_is_better,\n",
    "                                                          needs_proba=False))\n",
    "            self.model.fit(X, y)\n",
    "            \n",
    "        else:\n",
    "            for param in ParameterGrid(self.params):\n",
    "                self.model.set_params(**param)\n",
    "                self.model.fit(X, y)\n",
    "                val_pred = self.model.predict(val_X)\n",
    "                score = self.eval_fun(val_pred, val_y)\n",
    "                print(param, score)\n",
    "                if self.best_params_ is None or ((self.best_score_ <= score) == self.greater_is_better):\n",
    "                    self._best_model = self.model\n",
    "                    self.best_params_ = param\n",
    "                    self.best_score_ = score\n",
    "            \n",
    "            self.model = self._best_model\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "    \n",
    "    def evaluation(self, test_y, pred):\n",
    "        return self.model.evaluation(test_y, pred)\n",
    "\n",
    "class CustomRegModel:\n",
    "    def __init__(self):\n",
    "        self.model = RandomForestRegressor(random_state=RANDOM_SEED, n_jobs=4)\n",
    "    def train(self, X, y, params=None, val_X=None, val_y=None):\n",
    "        if params is not None:\n",
    "            self.model = CustomHyperParameterTuner(self.model, params, \n",
    "                                                   official_numerical_score, \n",
    "                                                   greater_is_better=True, cv=5)\n",
    "        self.model.fit(X, y, val_X, val_y)\n",
    "    def predict(self, X, use_round=True):\n",
    "        self.pred = self.model.predict(X)\n",
    "        if use_round:\n",
    "            self.pred = [round(x) for x in self.pred]\n",
    "        return self.pred\n",
    "    def evaluation(self, test_y, pred, pred_float=None):\n",
    "        self.ev = {}\n",
    "        self.ev['MSE'] = mean_squared_error(test_y, pred)\n",
    "        self.ev['Official Numerical Score'] = official_numerical_score(test_y, pred)\n",
    "        self.ev['MSE_not_round'] = mean_squared_error(test_y, pred_float)\n",
    "        self.ev['Official Numerical Score_not_round'] = official_numerical_score(test_y, pred_float)\n",
    "        return self.ev\n",
    "    def set_params(self, param):\n",
    "        self.model.set_params(param)\n",
    "\n",
    "class CustomClfModel:\n",
    "    def __init__(self):\n",
    "        self.model = RandomForestClassifier(random_state=RANDOM_SEED, n_jobs=4)\n",
    "    def train(self, X, y, params=None, val_X=None, val_y=None):\n",
    "        if params is not None:\n",
    "            self.model = CustomHyperParameterTuner(self.model, params, \n",
    "                                                   official_categorical_score, \n",
    "                                                   greater_is_better=True, cv=5)\n",
    "        self.model.fit(X, y, val_X, val_y)\n",
    "    def predict(self, X):\n",
    "        self.pred = self.model.predict(X)\n",
    "        return self.pred\n",
    "    def evaluation(self, test_y, pred, pred_float=None):\n",
    "        self.ev = {}\n",
    "        self.ev['ACC'] = accuracy_score(test_y, pred)\n",
    "        self.ev['Official Categorical Score'] = official_categorical_score(test_y, pred)\n",
    "        return self.ev\n",
    "    def set_params(self, param):\n",
    "        self.model.set_params(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/48\n",
      "key :  사망자수:주야/요일/중상자수/부상신고자수/발생지시도/발생지시군구/사고유형_대분류/사고유형_중분류/법규위반/도로형태_대분류/도로형태/당사자종별_1당_대분류/당사자종별_2당_대분류\n",
      "loc :  [0 1]\n",
      "tar_col :  사망자수\n",
      "dep_col :  ['주야', '요일', '중상자수', '부상신고자수', '발생지시도', '발생지시군구', '사고유형_대분류', '사고유형_중분류', '법규위반', '도로형태_대분류', '도로형태', '당사자종별_1당_대분류', '당사자종별_2당_대분류']\n",
      "{'n_estimators': 10} 2.0\n",
      "{'n_estimators': 20} 2.0\n",
      "{'n_estimators': 30} 1.9988895059442793\n",
      "{'n_estimators': 100} 1.9999000049998332\n",
      "{'n_estimators': 150} 1.9999555565431952\n",
      "{'n_estimators': 300} 1.9999555565431952\n",
      "{'n_estimators': 1000} 1.9999750003124974\n",
      "{'n_estimators': 1500} 1.9999888889506172\n",
      "{'n_estimators': 3000} 1.9999960000080002\n",
      "best parameter :  {'n_estimators': 20}\n",
      "val1 :  {'MSE': 0.06429712460063898, 'Official Numerical Score': 4858.887994554213, 'MSE_not_round': 0.059310258047344876, 'Official Numerical Score_not_round': 4856.164190319713}\n",
      "val2 :  {'MSE': 0.0, 'Official Numerical Score': 2.0, 'MSE_not_round': 2.0000000000000037e-06, 'Official Numerical Score_not_round': 1.9999960000080002}\n",
      "val2 shape :  (2, 24)\n",
      "\n",
      "2/48\n",
      "key :  사상자수:주야/요일/중상자수/부상신고자수/발생지시도/발생지시군구/사고유형_대분류/사고유형_중분류/법규위반/도로형태_대분류/도로형태/당사자종별_1당_대분류/당사자종별_2당_대분류\n",
      "loc :  [0 1]\n",
      "tar_col :  사상자수\n",
      "dep_col :  ['주야', '요일', '중상자수', '부상신고자수', '발생지시도', '발생지시군구', '사고유형_대분류', '사고유형_중분류', '법규위반', '도로형태_대분류', '도로형태', '당사자종별_1당_대분류', '당사자종별_2당_대분류']\n",
      "{'n_estimators': 10} 1.0655557672424734\n",
      "{'n_estimators': 20} 1.3286688803237654\n",
      "{'n_estimators': 30} 1.35025875578962\n",
      "{'n_estimators': 100} 1.2818106264426707\n",
      "{'n_estimators': 150} 1.2014437334620123\n",
      "{'n_estimators': 300} 1.117632702772407\n",
      "{'n_estimators': 1000} 1.1173644224208137\n",
      "{'n_estimators': 1500} 1.0932220940558954\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# main\n",
    "model_meta_dict = {}\n",
    "col_record = {}\n",
    "\n",
    "for _, row in test_data.iterrows():\n",
    "    target_col_list = []\n",
    "    dependent_col_list = []\n",
    "    for key, value in row.items():\n",
    "        if isinstance(value, float) and np.isnan(value):\n",
    "            target_col_list.append(key)\n",
    "        else:\n",
    "            dependent_col_list.append(key)\n",
    "    \n",
    "    for t_col in target_col_list:\n",
    "        col_key = t_col + ':' + '/'.join(dependent_col_list)\n",
    "        if col_record.get(col_key):\n",
    "            continue\n",
    "        model_dict = {}\n",
    "        model_dict['target_col'] = t_col\n",
    "        model_dict['dependent_col_list'] = dependent_col_list\n",
    "\n",
    "        if val_data is not None:\n",
    "            tmp_test_data = test_data.copy()\n",
    "            tmp_test_data = refine_val(tmp_test_data, target_col_list, dependent_col_list)\n",
    "            model_dict['val_data_loc'] = tmp_test_data.index\n",
    "    \n",
    "        model_meta_dict[col_key] = model_dict\n",
    "        col_record[col_key] = 1\n",
    "\n",
    "save_dict = {}\n",
    "loss_all_val1 = 0\n",
    "if val_data is not None:\n",
    "    loss_all_val2 = 0\n",
    "\n",
    "#tuned_parameters = {'n_estimators' : [1, 2, 3]}\n",
    "tuned_parameters = {'n_estimators' : [10, 20, 30, 100, 150, 300, 1000, 1500, 3000]}\n",
    "\n",
    "#tuned_parameters = None\n",
    "\n",
    "\n",
    "for i, model_dict_key in enumerate(model_meta_dict):\n",
    "    data = ori_data.copy()\n",
    "    model_dict = model_meta_dict[model_dict_key]\n",
    "    target_col = model_dict['target_col']\n",
    "    dependent_col_list = model_dict['dependent_col_list']\n",
    "    if val_data is not None:\n",
    "        tmp_val_data = val_data.iloc[model_dict['val_data_loc']]\n",
    "    result = {\n",
    "        'target_col' : target_col,\n",
    "        'dependent_col' : dependent_col_list\n",
    "    }\n",
    "    print(str(i+1) + '/' + str(len(model_meta_dict)))\n",
    "    print('key : ', model_dict_key)\n",
    "    print('loc : ', model_dict['val_data_loc'].values)\n",
    "    print('tar_col : ', target_col)\n",
    "    print('dep_col : ', dependent_col_list)\n",
    "\n",
    "    data['val'] = 0\n",
    "\n",
    "    if tmp_val_data is not None:\n",
    "        tmp_val_data['val'] = 1\n",
    "        data = data.append(tmp_val_data)\n",
    "\n",
    "    X = data[dependent_col_list + ['val']]\n",
    "    y = data[[target_col, 'val']]\n",
    "\n",
    "    X = preprocessing(X)\n",
    "\n",
    "    if tmp_val_data is not None:\n",
    "        val_X = X[X['val'] == 1]\n",
    "        val_y = y[y['val'] == 1]\n",
    "        X = X[X['val'] == 0]\n",
    "        y = y[y['val'] == 0]\n",
    "\n",
    "        val_X = val_X.drop(['val'], axis=1)\n",
    "        val_y = val_y[target_col].values\n",
    "\n",
    "    X = X.drop(['val'], axis=1)\n",
    "    y = y[target_col].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=RANDOM_SEED)\n",
    "    \n",
    "    if isinstance(y_test[0], str): # clf\n",
    "        model = CustomClfModel()\n",
    "    else:\n",
    "        model = CustomRegModel()\n",
    "    \n",
    "    model.train(X_train, y_train, tuned_parameters, val_X, val_y)\n",
    "    print('best parameter : ', model.model.best_params_)\n",
    "    pred = model.predict(X_test)\n",
    "    if not isinstance(y_test[0], str):\n",
    "        pred_float = model.predict(X_test, use_round=False)\n",
    "    else:\n",
    "        pred_float = None\n",
    "    val_eval = model.evaluation(y_test, pred, pred_float)\n",
    "    print('val1 : ', val_eval)\n",
    "    result['val_1'] = val_eval\n",
    "    loss_all_val1 = val_eval\n",
    "\n",
    "    if tmp_val_data is not None:\n",
    "        val_pred = model.predict(val_X)\n",
    "        if not isinstance(y_test[0], str):\n",
    "            val_pred_float = model.predict(val_X, use_round=False)\n",
    "        else:\n",
    "            val_pred_float = None\n",
    "        val_eval = model.evaluation(val_y, val_pred, val_pred_float)\n",
    "        print('val2 : ', val_eval)\n",
    "        result['val_2'] = val_eval\n",
    "        official_score_key = [v for v in val_eval if 'Official' in v][0]\n",
    "        loss_all_val2 += val_eval[official_score_key]\n",
    "        print('val2 shape : ', tmp_val_data.shape)\n",
    "\n",
    "    print()\n",
    "    save_dict[i] = result\n",
    "    \n",
    "    model_meta_dict[model_dict_key]['model'] = model\n",
    "\n",
    "save_dict['loss_all_val1'] = loss_all_val1\n",
    "save_dict['loss_all_val2'] = loss_all_val2\n",
    "\n",
    "now_string = str(datetime.datetime.now())\n",
    "now_string = now_string.replace(':', '-')\n",
    "now_string = str(round(loss_all_val2, 4)).zfill(8) + ' ' + now_string\n",
    "with open('result/' + now_string + '.json', 'w') as f:\n",
    "    json.dump(save_dict, f)\n",
    "with open('result/' + now_string + '.p', 'wb') as f:\n",
    "    pickle.dump(model_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check save file\n",
    "with open('result/' + now_string + '.json', 'r') as f:\n",
    "    json_ = json.load(f)\n",
    "    \n",
    "with open('result/' + now_string + '.p', 'rb') as f:\n",
    "    model_ = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "debug_log = model_meta_dict['사고유형_대분류:주야/요일/사망자수/사상자수/중상자수/경상자수/부상신고자수/발생지시도/발생지시군구/도로형태_대분류/도로형태/당사자종별_1당_대분류/당사자종별_2당_대분류']['val_data_loc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.CustomHyperParameterTuner at 0x1064ef98>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
